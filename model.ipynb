{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437bea88-36ca-4e30-8983-8f378096b900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Import DataSets\n",
    "\n",
    "# Read the csv file\n",
    "df = pd.read_csv('data_train.csv')\n",
    "y_test = pd.read_csv('test_competition.csv')\n",
    "\n",
    "\n",
    "Y_train = df[\"default.payment.next.month\"]\n",
    "\n",
    "X_train = df.drop(columns = [\"default.payment.next.month\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f54085a7-0d5c-4044-8b74-c5ef156492a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib \n",
    "\n",
    "# #Splitting DataFrame\n",
    "# X_train = df.iloc[:20000,:]\n",
    "\n",
    "# Y_train = X_train[\"default.payment.next.month\"]\n",
    "\n",
    "# X_train = X_train.drop(columns = [\"default.payment.next.month\"])\n",
    "\n",
    "\n",
    "\n",
    "# y_test = df.iloc[20000:,:]\n",
    "\n",
    "# y_test.to_csv(\"test_5000.csv\", index=False)\n",
    "\n",
    "# y_test = y_test.drop(columns = [\"default.payment.next.month\"])\n",
    "# print(y_test)\n",
    "\n",
    "\n",
    "\n",
    "# # # \n",
    "# # y_test = df.iloc[20000:,:]\n",
    "# # y_test = y_test.drop(columns = [\"default.payment.next.month\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc61613-afa1-4d9b-a006-a8e71999912c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using smote to overSample minorities in the dataset for avoiding bias\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# print(\"Smoting...\")\n",
    "\n",
    "# # Step 2: Apply SMOTE to the training data\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train, Y_train = smote.fit_resample(X_train, Y_train)\n",
    "\n",
    "# print(\"Data over sampled !\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c8aee1d-5919-40aa-9fd1-17393adc6100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading RandomForestClassifier...\n",
      "Loading GridSearchCV model...\n",
      "Fitting GridSearchCV model...\n",
      "Fitting 7 folds for each of 12 candidates, totalling 84 fits\n",
      "GridSearchCV fitted\n",
      "\n",
      "Best parameters found:\n",
      "max_depth: 10\n",
      "n_estimators: 200\n",
      "\n",
      "Best roc_auc score: 77.98%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def bestModelFindingWithRandomForest(param_grid, scoring, X_train, Y_train, X_train_reshape=False, Y_train_reshape=False):\n",
    "    \"\"\"\n",
    "    Find best Random Forest model using GridSearchCV\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    param_grid : dict\n",
    "        Parameter grid for GridSearchCV\n",
    "    scoring : str\n",
    "        Scoring metric ('roc_auc', 'accuracy', etc.)\n",
    "    X_train : array-like\n",
    "        Training features\n",
    "    Y_train : array-like\n",
    "        Training labels\n",
    "    X_train_reshape : bool\n",
    "        Whether to reshape X_train\n",
    "    Y_train_reshape : bool\n",
    "        Whether to reshape Y_train\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Loading RandomForestClassifier...\")\n",
    "        model = RandomForestClassifier(random_state=100)\n",
    "        \n",
    "        if X_train_reshape:\n",
    "            print(\"Reshaping X_train...\")\n",
    "            X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "            \n",
    "        if Y_train_reshape:\n",
    "            print(\"Reshaping Y_train...\")\n",
    "            Y_train = Y_train.reshape(Y_train.shape[0], -1)\n",
    "            \n",
    "        print(\"Loading GridSearchCV model...\")\n",
    "        # Using GridSearchCV with 10-fold cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=7,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        print(\"Fitting GridSearchCV model...\")\n",
    "        # Fit the model to find the best hyperparameters\n",
    "        grid_search.fit(X_train, Y_train)\n",
    "        \n",
    "        print(\"GridSearchCV fitted\")\n",
    "        \n",
    "        # Best parameters and score obtained\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_ * 100  # In percentage\n",
    "        \n",
    "        print(\"\\nBest parameters found:\")\n",
    "        for param, value in best_params.items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        print(f\"\\nBest {scoring} score: {best_score:.2f}%\")\n",
    "        \n",
    "        return grid_search.best_estimator_\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],           # Number of trees\n",
    "    'max_depth': [10, 15, 20, 25],             # Tree depth\n",
    "    # 'class_weight': ['balanced']               # Class weight\n",
    "}\n",
    "\n",
    "\n",
    "bestModel = bestModelFindingWithRandomForest(param_grid, \"roc_auc\", X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f08da7-51ed-4514-9798-799ba3b5ae44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.12/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from lightgbm) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7be8528a-8908-46b8-b051-8e8fad615361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lightgbm...\n",
      "Loading GridSearch model...\n",
      "Fitting GridSearch model...\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "GridSearch fitted\n",
      "\n",
      "Best parameters found:\n",
      "learning_rate: 0.01\n",
      "max_depth: 5\n",
      "n_estimators: 600\n",
      "num_leaves: 63\n",
      "\n",
      "Best roc_auc score: 78.25%\n"
     ]
    }
   ],
   "source": [
    "# METHOD 2\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def bestModelFinding(param_grid, scoring, X_train, Y_train):\n",
    "    \"\"\"\n",
    "    Find the best LightGBM model using GridSearchCV\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    param_grid : dict\n",
    "        Parameter grid for GridSearchCV\n",
    "    scoring : str\n",
    "        Scoring metric ('roc_auc', 'accuracy', etc.)\n",
    "    X_train : array-like\n",
    "        Training features\n",
    "    Y_train : array-like\n",
    "        Training labels\n",
    "    \"\"\"\n",
    "    # Base parameters for the model\n",
    "    base_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Loading model\n",
    "        print(\"Loading lightgbm...\")\n",
    "        # Initialize the LGBMClassifier with base parameters\n",
    "        model = lgb.LGBMClassifier(**base_params)\n",
    "        \n",
    "        print(\"Loading GridSearch model...\")\n",
    "        # Configure GridSearchCV with 5-fold cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grid,\n",
    "            cv=5,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1,\n",
    "            verbose=1  #for progress tracking\n",
    "        )\n",
    "        \n",
    "        print(\"Fitting GridSearch model...\")\n",
    "        # Fit the GridSearch model to find the best hyperparameters\n",
    "        grid_search.fit(X_train, Y_train)\n",
    "        print(\"GridSearch fitted\")\n",
    "        \n",
    "        # Best parameters and best score found\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = grid_search.best_score_ * 100  # In percentage\n",
    "        \n",
    "        print(\"\\nBest parameters found:\")\n",
    "        for param, value in best_params.items():\n",
    "            print(f\"{param}: {value}\")\n",
    "        print(f\"\\nBest {scoring} score: {best_score:.2f}%\")\n",
    "        \n",
    "        return grid_search.best_estimator_\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Define your parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [600,900],\n",
    "    'learning_rate': [0.01, 0.08 ,0.05],\n",
    "    'max_depth': [5,10, 25],\n",
    "    'num_leaves': [63 ,100,120]\n",
    "}\n",
    "\n",
    "# param_grid = { 78.21%\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1],\n",
    "#     'max_depth': [-1, 3, 5, 7],\n",
    "#     'num_leaves': [31, 63, 127],\n",
    "#     'min_child_samples': [20, 50],\n",
    "#     'subsample': [0.8, 1.0],\n",
    "#     'colsample_bytree': [0.8, 1.0]\n",
    "# }\n",
    "\n",
    "# Find the best model\n",
    "bestModel = bestModelFinding(param_grid, \"roc_auc\", X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1d7174b-2f8b-44e6-93b0-451eaf7999fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Prediction step\n",
    "print(\"Predicting...\")\n",
    "predicted_survival = bestModel.predict_proba(y_test)  \n",
    "\n",
    "# Extracting the first column of predicted probabilities\n",
    "unsortedPredictedPaymentValue = predicted_survival[:, 1]\n",
    "\n",
    "# Combining Passenger ID and predicted payment probabilities into a DataFrame\n",
    "predicted_df = pd.DataFrame({\n",
    "    'ID': y_test['ID'],      # Get the PassengerId from y_test\n",
    "    'PAYED': unsortedPredictedPaymentValue  # Add the predicted payment probability (class 0)\n",
    "})\n",
    "\n",
    "# Sort predicted_df by the 'PAYED' column in descending order and extract sorted IDs\n",
    "sorted_df = predicted_df.sort_values(by='PAYED', ascending=False)[['ID']]\n",
    "\n",
    "# Display the resulting DataFrame of sorted IDs\n",
    "\n",
    "sorted_df.head(1000).to_csv(\"sorted_df.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
